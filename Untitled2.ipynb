{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duong2000x10/ChatBot/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Akwcp54Rgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "259d7896-4fbe-498d-a55a-336c0e064e42"
      },
      "source": [
        "!git clone https://github.com/tensorflow/nmt/\n",
        "!/content/nmt/nmt/scripts/download_iwslt15.sh /content/nmt/tmp/nmt_data\n",
        "!mkdir /content/nmt/tmp/nmt_model\n",
        "%cd nmt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nmt'...\n",
            "remote: Enumerating objects: 1283, done.\u001b[K\n",
            "remote: Total 1283 (delta 0), reused 0 (delta 0), pack-reused 1283\u001b[K\n",
            "Receiving objects: 100% (1283/1283), 1.24 MiB | 1.36 MiB/s, done.\n",
            "Resolving deltas: 100% (918/918), done.\n",
            "mkdir: created directory '/content/nmt/tmp'\n",
            "mkdir: created directory '/content/nmt/tmp/nmt_data'\n",
            "Download training dataset train.en and train.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.9M  100 12.9M    0     0  1517k      0  0:00:08  0:00:08 --:--:-- 2259k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17.2M  100 17.2M    0     0  3573k      0  0:00:04  0:00:04 --:--:-- 3795k\n",
            "Download dev dataset tst2012.en and tst2012.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0   109k      0  0:00:01  0:00:01 --:--:--  109k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  183k  100  183k    0     0   130k      0  0:00:01  0:00:01 --:--:--  130k\n",
            "Download test dataset tst2013.en and tst2013.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  129k  100  129k    0     0   115k      0  0:00:01  0:00:01 --:--:--  115k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  179k  100  179k    0     0   125k      0  0:00:01  0:00:01 --:--:--  125k\n",
            "Download vocab file vocab.en and vocab.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0   108k      0  0:00:01  0:00:01 --:--:--  108k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 46767  100 46767    0     0  54826      0 --:--:-- --:--:-- --:--:-- 54762\n",
            "/content/nmt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU2lrIkL4YwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aac72b9c-3831-4be2-eadf-d08441615ddf"
      },
      "source": [
        "!python -m nmt.nmt \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=/content/nmt/tmp/nmt_data/vocab  \\\n",
        "    --train_prefix=/content/nmt/tmp/nmt_data/train \\\n",
        "    --dev_prefix=/content/nmt/tmp/nmt_data/tst2012  \\\n",
        "    --test_prefix=/content/nmt/tmp/nmt_data/tst2013 \\\n",
        "    --out_dir=/content/nmt/tmp/nmt_model \\\n",
        "    --num_train_steps=12000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --num_layers=2 \\\n",
        "    --num_units=128 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:707: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1104 19:27:09.236039 139681884108672 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I1104 19:27:10.214441 139681884108672 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "# Job id 0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:629: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1104 19:27:11.232067 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/nmt.py:629: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-11-04 19:27:11.238507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-04 19:27:11.296586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:11.297344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-04 19:27:11.311448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-04 19:27:11.498208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-04 19:27:11.599090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-04 19:27:11.631045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-04 19:27:11.882262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-04 19:27:12.051585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-04 19:27:12.527829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-04 19:27:12.528123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.528980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.529663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-04 19:27:12.549261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-11-04 19:27:12.549524: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x261f100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-04 19:27:12.549559: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-04 19:27:12.640010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.640858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x261f2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-04 19:27:12.640888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-11-04 19:27:12.642245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.642914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-04 19:27:12.642984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-04 19:27:12.643011: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-04 19:27:12.643034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-04 19:27:12.643057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-04 19:27:12.643079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-04 19:27:12.643102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-04 19:27:12.643126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-04 19:27:12.643235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.643955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.644636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-04 19:27:12.648413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-04 19:27:12.650078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-04 19:27:12.650112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-04 19:27:12.650126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-04 19:27:12.651550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.652347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:12.653120: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-11-04 19:27:12.653183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 15127573158635264000), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 8809625573187650997), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 6508837675482450297), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 11330115994, 8827316864352753485)]\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:640: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W1104 19:27:12.654589 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/nmt.py:640: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "# Vocab file /content/nmt/tmp/nmt_data/vocab.vi exists\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/vocab_utils.py:103: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1104 19:27:12.655043 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/utils/vocab_utils.py:103: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "# Vocab file /content/nmt/tmp/nmt_data/vocab.en exists\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:548: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1104 19:27:12.694330 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/nmt.py:548: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/best_bleu/hparams\n",
            "  attention=\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=0\n",
            "  best_bleu=0\n",
            "  best_bleu_dir=/content/nmt/tmp/nmt_model/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  coverage_penalty_weight=0.0\n",
            "  decay_scheme=\n",
            "  dev_prefix=/content/nmt/tmp/nmt_data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=uni\n",
            "  eos=</s>\n",
            "  epoch_step=0\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=greedy\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=1.0\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=12000\n",
            "  num_translations_per_input=1\n",
            "  num_units=128\n",
            "  optimizer=sgd\n",
            "  out_dir=/content/nmt/tmp/nmt_model\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=/content/nmt/tmp/nmt_data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=/content/nmt/tmp/nmt_data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=/content/nmt/tmp/nmt_data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=/content/nmt/tmp/nmt_data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=/content/nmt/tmp/nmt_data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:90: The name tf.container is deprecated. Please use tf.compat.v1.container instead.\n",
            "\n",
            "W1104 19:27:12.696250 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:90: The name tf.container is deprecated. Please use tf.compat.v1.container instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:94: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1104 19:27:12.711621 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:94: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:96: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1104 19:27:12.749952 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:96: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "W1104 19:27:13.134382 139681884108672 deprecation.py:323] From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1104 19:27:13.141239 139681884108672 deprecation.py:323] From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:239: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W1104 19:27:13.313038 139681884108672 deprecation.py:323] From /content/nmt/nmt/utils/iterator_utils.py:239: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:162: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W1104 19:27:13.323837 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:162: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1104 19:27:13.324136 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:285: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W1104 19:27:13.324599 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:285: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "# Creating train graph ...\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:375: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "W1104 19:27:13.340743 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:375: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "# Build a basic encoder\n",
            "  num_layers = 2, num_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W1104 19:27:13.345603 139681884108672 deprecation.py:323] From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W1104 19:27:13.354743 139681884108672 deprecation.py:323] From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W1104 19:27:13.355512 139681884108672 deprecation.py:323] From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W1104 19:27:13.456487 139681884108672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1104 19:27:13.465611 139681884108672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1104 19:27:13.523406 139681884108672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1104 19:27:13.553065 139681884108672 deprecation.py:323] From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1104 19:27:13.556284 139681884108672 deprecation.py:323] From /content/nmt/nmt/model.py:445: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:190: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W1104 19:27:13.882865 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:190: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "  learning_rate=1, warmup_steps=0, warmup_scheme=t2t\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:248: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W1104 19:27:13.883737 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:248: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "  decay_scheme=, start_decay_step=12000, decay_steps 0, decay_factor 1\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:295: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W1104 19:27:13.902861 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:295: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:203: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "W1104 19:27:13.911421 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:203: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:515: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W1104 19:27:15.151449 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:515: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:517: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
            "\n",
            "W1104 19:27:15.153213 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:517: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:321: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W1104 19:27:15.181431 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:321: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:100: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1104 19:27:15.185259 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:100: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:101: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W1104 19:27:15.185450 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model.py:101: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "# Creating eval graph ...\n",
            "# Build a basic encoder\n",
            "  num_layers = 2, num_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_layers = 2, num_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), \n",
            "# log_file=/content/nmt/tmp/nmt_model/log_1572895636\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/misc_utils.py:142: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W1104 19:27:16.328870 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/utils/misc_utils.py:142: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-11-04 19:27:16.329654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.330443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-04 19:27:16.330548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-04 19:27:16.330576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-04 19:27:16.330598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-04 19:27:16.330621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-04 19:27:16.330643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-04 19:27:16.330665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-04 19:27:16.330688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-04 19:27:16.330793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.331646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.332368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-04 19:27:16.332456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-04 19:27:16.332471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-04 19:27:16.332482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-04 19:27:16.332636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.333508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.334238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-11-04 19:27:16.334728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.335489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-04 19:27:16.335552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-04 19:27:16.335580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-04 19:27:16.335614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-04 19:27:16.335636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-04 19:27:16.335661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-04 19:27:16.335683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-04 19:27:16.335705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-04 19:27:16.335799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.336584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.337304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-04 19:27:16.337341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-04 19:27:16.337355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-04 19:27:16.337365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-04 19:27:16.337492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.338226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.338930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-11-04 19:27:16.339457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.340115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-04 19:27:16.340154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-04 19:27:16.340215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-04 19:27:16.340260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-04 19:27:16.340295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-04 19:27:16.340323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-04 19:27:16.340344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-04 19:27:16.340366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-04 19:27:16.340469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.341273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.341979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-04 19:27:16.342007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-04 19:27:16.342020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-04 19:27:16.342029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-04 19:27:16.342136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.342976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-04 19:27:16.343705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:628: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "W1104 19:27:16.343934 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:628: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:629: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
            "\n",
            "W1104 19:27:19.048404 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/model_helper.py:629: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
            "\n",
            "  created train model with fresh parameters, time 2.79s\n",
            "WARNING:tensorflow:From /content/nmt/nmt/train.py:500: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W1104 19:27:19.161941 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/train.py:500: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "  created infer model with fresh parameters, time 0.08s\n",
            "  # 806\n",
            "2019-11-04 19:27:19.815043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "    src: Lc l ln cui bn nghe ai  ni v sai lm , ri sai lm , ri sai lm ?\n",
            "    ref: When was the last time you heard somebody talk about failure after failure after failure ?\n",
            "    nmt: geologists Phil Phil principles principles principles principles houses houses stripping stripping stripping stripping diagnosed laser laser laser laser laser homegrown laser M.D. M.D. humbled humbled humbled humbled humbled humbled humbled manuscript manuscript manuscript scriptures scriptures chemicals scriptures Motor Motor squeeze aortic squeeze\n",
            "  created eval model with fresh parameters, time 0.09s\n",
            "  eval dev: perplexity 17187.43, time 1s, Mon Nov  4 19:27:22 2019.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/misc_utils.py:134: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "W1104 19:27:22.361898 139681884108672 module_wrapper.py:139] From /content/nmt/nmt/utils/misc_utils.py:134: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "  eval test: perplexity 17186.75, time 1s, Mon Nov  4 19:27:23 2019.\n",
            "  created infer model with fresh parameters, time 0.08s\n",
            "# Start step 0, lr 1, Mon Nov  4 19:27:23 2019\n",
            "# Init train iterator, skipping 0 elements\n",
            "  step 100 lr 1 step-time 0.29s wps 18.86K ppl 1776.81 gN 15.03 bleu 0.00, Mon Nov  4 19:27:53 2019\n",
            "  step 200 lr 1 step-time 0.29s wps 19.71K ppl 594.00 gN 6.82 bleu 0.00, Mon Nov  4 19:28:21 2019\n",
            "  step 300 lr 1 step-time 0.16s wps 36.32K ppl 378.63 gN 4.89 bleu 0.00, Mon Nov  4 19:28:37 2019\n",
            "  step 400 lr 1 step-time 0.15s wps 36.19K ppl 280.75 gN 4.36 bleu 0.00, Mon Nov  4 19:28:52 2019\n",
            "  step 500 lr 1 step-time 0.16s wps 36.51K ppl 234.40 gN 4.01 bleu 0.00, Mon Nov  4 19:29:08 2019\n",
            "  step 600 lr 1 step-time 0.15s wps 36.29K ppl 202.15 gN 3.51 bleu 0.00, Mon Nov  4 19:29:24 2019\n",
            "  step 700 lr 1 step-time 0.16s wps 36.04K ppl 180.35 gN 3.28 bleu 0.00, Mon Nov  4 19:29:39 2019\n",
            "  step 800 lr 1 step-time 0.16s wps 36.28K ppl 170.37 gN 3.30 bleu 0.00, Mon Nov  4 19:29:55 2019\n",
            "  step 900 lr 1 step-time 0.16s wps 35.76K ppl 155.97 gN 3.04 bleu 0.00, Mon Nov  4 19:30:10 2019\n",
            "  step 1000 lr 1 step-time 0.16s wps 36.23K ppl 150.50 gN 3.20 bleu 0.00, Mon Nov  4 19:30:26 2019\n",
            "# Save eval, global step 1000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "I1104 19:30:26.751809 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000, time 0.08s\n",
            "  # 1240\n",
            "    src: Khi bt u chng trnh ny , ti khng bit my v chnh ph .\n",
            "    ref: Now I didn &apos;t know very much about government when I started this program .\n",
            "    nmt: So , the first thing that the way that the way you do .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "I1104 19:30:26.883021 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000, time 0.08s\n",
            "  eval dev: perplexity 115.40, time 1s, Mon Nov  4 19:30:28 2019.\n",
            "  eval test: perplexity 133.15, time 1s, Mon Nov  4 19:30:29 2019.\n",
            "# Finished an epoch, step 1043. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "I1104 19:30:36.268082 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000, time 0.05s\n",
            "  # 501\n",
            "    src: Ci Nu bn ngh n phim &quot; Avata &quot; nu bn ngh v vic mi n  lay ng mi ngi nh th no-- ng   n cu chuyn Pocahontas lm g-- Ti sao li b lay ng bi biu tng n th\n",
            "    ref: And if you think about &quot; Avatar , &quot; if you think of why people were so touched by it -- never mind the Pocahontas story -- why so touched by the imagery ?\n",
            "    nmt: So , the first thing that the way that the way that the way that the way that the way that the way that the way that the way that the way that the way you have to do the way .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "I1104 19:30:36.422412 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-1000, time 0.05s\n",
            "# External evaluation, global step 1000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 11s, Mon Nov  4 19:30:47 2019.\n",
            "  bleu dev: 0.3\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 1000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 11s, Mon Nov  4 19:30:59 2019.\n",
            "  bleu test: 0.4\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 1100 lr 1 step-time 0.24s wps 22.83K ppl 139.77 gN 3.20 bleu 0.27, Mon Nov  4 19:31:17 2019\n",
            "  step 1200 lr 1 step-time 0.28s wps 19.62K ppl 131.11 gN 2.94 bleu 0.27, Mon Nov  4 19:31:45 2019\n",
            "  step 1300 lr 1 step-time 0.20s wps 27.79K ppl 125.90 gN 2.97 bleu 0.27, Mon Nov  4 19:32:05 2019\n",
            "  step 1400 lr 1 step-time 0.16s wps 36.19K ppl 120.71 gN 2.89 bleu 0.27, Mon Nov  4 19:32:21 2019\n",
            "  step 1500 lr 1 step-time 0.16s wps 36.21K ppl 118.18 gN 2.97 bleu 0.27, Mon Nov  4 19:32:37 2019\n",
            "  step 1600 lr 1 step-time 0.16s wps 35.86K ppl 112.91 gN 2.93 bleu 0.27, Mon Nov  4 19:32:52 2019\n",
            "  step 1700 lr 1 step-time 0.16s wps 36.34K ppl 110.60 gN 2.93 bleu 0.27, Mon Nov  4 19:33:08 2019\n",
            "  step 1800 lr 1 step-time 0.16s wps 36.05K ppl 106.07 gN 2.91 bleu 0.27, Mon Nov  4 19:33:23 2019\n",
            "  step 1900 lr 1 step-time 0.16s wps 36.64K ppl 104.27 gN 2.89 bleu 0.27, Mon Nov  4 19:33:39 2019\n",
            "  step 2000 lr 1 step-time 0.15s wps 36.13K ppl 97.29 gN 2.73 bleu 0.27, Mon Nov  4 19:33:54 2019\n",
            "# Save eval, global step 2000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "I1104 19:33:55.043965 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000, time 0.06s\n",
            "  # 269\n",
            "    src: Nh th qu v lng tm\n",
            "    ref: It would be unconscionable .\n",
            "    nmt: And this is a very good .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "I1104 19:33:55.131717 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000, time 0.06s\n",
            "  eval dev: perplexity 82.18, time 1s, Mon Nov  4 19:33:56 2019.\n",
            "  eval test: perplexity 97.18, time 1s, Mon Nov  4 19:33:57 2019.\n",
            "# Finished an epoch, step 2086. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "I1104 19:34:11.045726 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000, time 0.06s\n",
            "  # 1305\n",
            "    src: H s dng i bn tay ca mnh  vit ln nhng ng dng gip chnh ph lm vic tt hn .\n",
            "    ref: They &apos;re using their hands to write applications that make government work better .\n",
            "    nmt: They &apos;re not <unk> , but they &apos;re not <unk> , but they &apos;re not <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "I1104 19:34:11.164100 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-2000, time 0.05s\n",
            "# External evaluation, global step 2000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 10s, Mon Nov  4 19:34:21 2019.\n",
            "  bleu dev: 1.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 2000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 10s, Mon Nov  4 19:34:32 2019.\n",
            "  bleu test: 0.9\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 2100 lr 1 step-time 0.18s wps 29.85K ppl 95.17 gN 2.98 bleu 1.78, Mon Nov  4 19:34:37 2019\n",
            "  step 2200 lr 1 step-time 0.28s wps 19.42K ppl 91.06 gN 2.88 bleu 1.78, Mon Nov  4 19:35:05 2019\n",
            "  step 2300 lr 1 step-time 0.27s wps 21.32K ppl 90.66 gN 2.80 bleu 1.78, Mon Nov  4 19:35:32 2019\n",
            "  step 2400 lr 1 step-time 0.16s wps 35.89K ppl 87.49 gN 2.91 bleu 1.78, Mon Nov  4 19:35:48 2019\n",
            "  step 2500 lr 1 step-time 0.16s wps 36.28K ppl 86.19 gN 2.89 bleu 1.78, Mon Nov  4 19:36:03 2019\n",
            "  step 2600 lr 1 step-time 0.15s wps 36.16K ppl 84.79 gN 2.89 bleu 1.78, Mon Nov  4 19:36:19 2019\n",
            "  step 2700 lr 1 step-time 0.16s wps 36.15K ppl 82.63 gN 2.88 bleu 1.78, Mon Nov  4 19:36:35 2019\n",
            "  step 2800 lr 1 step-time 0.15s wps 36.06K ppl 80.07 gN 2.85 bleu 1.78, Mon Nov  4 19:36:50 2019\n",
            "  step 2900 lr 1 step-time 0.16s wps 36.22K ppl 78.91 gN 2.85 bleu 1.78, Mon Nov  4 19:37:06 2019\n",
            "  step 3000 lr 1 step-time 0.16s wps 36.17K ppl 78.82 gN 2.97 bleu 1.78, Mon Nov  4 19:37:21 2019\n",
            "# Save eval, global step 3000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "I1104 19:37:22.058037 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000, time 0.05s\n",
            "  # 1407\n",
            "    src: Ai  c th ngh rng y ch l bc nh phong cnh v phn  di  c chnh sa .\n",
            "    ref: One might think that this is just an image of a landscape and the lower part is what &apos;s manipulated .\n",
            "    nmt: There &apos;s a <unk> of the <unk> <unk> of the <unk> <unk> of the <unk> <unk> <unk> <unk> <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "I1104 19:37:22.173611 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000, time 0.06s\n",
            "  eval dev: perplexity 75.49, time 1s, Mon Nov  4 19:37:23 2019.\n",
            "  eval test: perplexity 88.74, time 1s, Mon Nov  4 19:37:24 2019.\n",
            "  step 3100 lr 1 step-time 0.16s wps 35.86K ppl 76.71 gN 2.78 bleu 1.78, Mon Nov  4 19:37:40 2019\n",
            "# Finished an epoch, step 3129. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "I1104 19:37:44.948829 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000, time 0.05s\n",
            "  # 672\n",
            "    src: Tin th ,  l mt cu th p bng c 10 ln c 4 ln an ton .\n",
            "    ref: That &apos;s somebody who hit , by the way , four times safely out of every 10 .\n",
            "    nmt: In the first time , the <unk> <unk> was the <unk> <unk> <unk> <unk> <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "I1104 19:37:45.053889 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-3000, time 0.05s\n",
            "# External evaluation, global step 3000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 11s, Mon Nov  4 19:37:56 2019.\n",
            "  bleu dev: 1.2\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 3000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 11s, Mon Nov  4 19:38:07 2019.\n",
            "  bleu test: 0.9\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 3200 lr 1 step-time 0.25s wps 21.93K ppl 73.75 gN 3.10 bleu 1.78, Mon Nov  4 19:38:28 2019\n",
            "  step 3300 lr 1 step-time 0.28s wps 20.03K ppl 73.08 gN 2.91 bleu 1.78, Mon Nov  4 19:38:56 2019\n",
            "  step 3400 lr 1 step-time 0.20s wps 28.19K ppl 71.42 gN 2.92 bleu 1.78, Mon Nov  4 19:39:16 2019\n",
            "  step 3500 lr 1 step-time 0.15s wps 36.27K ppl 69.72 gN 2.92 bleu 1.78, Mon Nov  4 19:39:31 2019\n",
            "  step 3600 lr 1 step-time 0.16s wps 36.45K ppl 68.74 gN 2.88 bleu 1.78, Mon Nov  4 19:39:47 2019\n",
            "  step 3700 lr 1 step-time 0.16s wps 36.23K ppl 67.78 gN 2.88 bleu 1.78, Mon Nov  4 19:40:03 2019\n",
            "  step 3800 lr 1 step-time 0.16s wps 36.11K ppl 66.91 gN 2.83 bleu 1.78, Mon Nov  4 19:40:18 2019\n",
            "  step 3900 lr 1 step-time 0.15s wps 36.29K ppl 65.97 gN 2.84 bleu 1.78, Mon Nov  4 19:40:34 2019\n",
            "  step 4000 lr 1 step-time 0.16s wps 36.36K ppl 66.78 gN 2.93 bleu 1.78, Mon Nov  4 19:40:49 2019\n",
            "# Save eval, global step 4000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "I1104 19:40:50.126564 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000, time 0.06s\n",
            "  # 567\n",
            "    src: H lun lo lng h s sp sa mt v tr ca h\n",
            "    ref: They &apos;re always worried they &apos;re going to lose shelf space .\n",
            "    nmt: They &apos;re going to be able to be able to do their own <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "I1104 19:40:50.238715 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000, time 0.06s\n",
            "  eval dev: perplexity 59.11, time 1s, Mon Nov  4 19:40:51 2019.\n",
            "  eval test: perplexity 69.25, time 1s, Mon Nov  4 19:40:52 2019.\n",
            "  step 4100 lr 1 step-time 0.15s wps 36.16K ppl 63.67 gN 2.81 bleu 1.78, Mon Nov  4 19:41:08 2019\n",
            "# Finished an epoch, step 4172. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "I1104 19:41:19.379014 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000, time 0.06s\n",
            "  # 1043\n",
            "    src: N  xa cch khi chng ta tin ti n .\n",
            "    ref: It &apos;s about as far as we go out .\n",
            "    nmt: It &apos;s going to be very important to us .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "I1104 19:41:19.481020 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-4000, time 0.05s\n",
            "# External evaluation, global step 4000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 16s, Mon Nov  4 19:41:36 2019.\n",
            "  bleu dev: 2.1\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 4000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 15s, Mon Nov  4 19:41:52 2019.\n",
            "  bleu test: 1.5\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 4200 lr 1 step-time 0.20s wps 27.25K ppl 61.75 gN 2.91 bleu 2.07, Mon Nov  4 19:42:01 2019\n",
            "  step 4300 lr 1 step-time 0.29s wps 19.48K ppl 60.83 gN 2.89 bleu 2.07, Mon Nov  4 19:42:30 2019\n",
            "  step 4400 lr 1 step-time 0.24s wps 23.24K ppl 59.32 gN 2.83 bleu 2.07, Mon Nov  4 19:42:54 2019\n",
            "  step 4500 lr 1 step-time 0.16s wps 36.38K ppl 60.37 gN 3.03 bleu 2.07, Mon Nov  4 19:43:09 2019\n",
            "  step 4600 lr 1 step-time 0.16s wps 36.25K ppl 59.70 gN 2.92 bleu 2.07, Mon Nov  4 19:43:25 2019\n",
            "  step 4700 lr 1 step-time 0.15s wps 36.52K ppl 58.26 gN 3.00 bleu 2.07, Mon Nov  4 19:43:40 2019\n",
            "  step 4800 lr 1 step-time 0.16s wps 36.25K ppl 58.86 gN 2.95 bleu 2.07, Mon Nov  4 19:43:56 2019\n",
            "  step 4900 lr 1 step-time 0.15s wps 36.09K ppl 57.86 gN 2.95 bleu 2.07, Mon Nov  4 19:44:11 2019\n",
            "  step 5000 lr 1 step-time 0.16s wps 36.14K ppl 57.58 gN 2.85 bleu 2.07, Mon Nov  4 19:44:27 2019\n",
            "# Save eval, global step 5000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "I1104 19:44:27.587084 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000, time 0.05s\n",
            "  # 1081\n",
            "    src: Bi v vy m , v d , s khng thuc khng sinh c hnh thnh .\n",
            "    ref: Now that &apos;s why , for instance , antibiotic resistance has evolved .\n",
            "    nmt: So , the question is , is the most important thing in the world .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "I1104 19:44:27.695747 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000, time 0.06s\n",
            "  eval dev: perplexity 46.98, time 1s, Mon Nov  4 19:44:29 2019.\n",
            "  eval test: perplexity 54.47, time 1s, Mon Nov  4 19:44:30 2019.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "I1104 19:44:30.604928 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000, time 0.05s\n",
            "  # 829\n",
            "    src: Ti khng phi r-bt ; khng phi ln no ti cng theo y mt qui trnh .\n",
            "    ref: I &apos;m not a robot ; I don &apos;t do things the same way each time .\n",
            "    nmt: I don &apos;t have no idea of the <unk> of the <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "I1104 19:44:30.713652 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000, time 0.05s\n",
            "# External evaluation, global step 5000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 11s, Mon Nov  4 19:44:41 2019.\n",
            "  bleu dev: 3.5\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 5000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 10s, Mon Nov  4 19:44:53 2019.\n",
            "  bleu test: 2.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 5100 lr 1 step-time 0.16s wps 35.93K ppl 58.25 gN 2.99 bleu 3.54, Mon Nov  4 19:45:09 2019\n",
            "  step 5200 lr 1 step-time 0.15s wps 36.10K ppl 55.85 gN 2.84 bleu 3.54, Mon Nov  4 19:45:24 2019\n",
            "# Finished an epoch, step 5215. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "I1104 19:45:27.269063 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000, time 0.05s\n",
            "  # 847\n",
            "    src: Tn ti l Brian Goldman .\n",
            "    ref: My name is Brian Goldman .\n",
            "    nmt: My name is a <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "I1104 19:45:27.365490 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-5000, time 0.05s\n",
            "# External evaluation, global step 5000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 11s, Mon Nov  4 19:45:38 2019.\n",
            "  bleu dev: 3.5\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 5000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 11s, Mon Nov  4 19:45:50 2019.\n",
            "  bleu test: 2.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 5300 lr 1 step-time 0.28s wps 19.72K ppl 53.97 gN 3.25 bleu 3.54, Mon Nov  4 19:46:15 2019\n",
            "  step 5400 lr 1 step-time 0.28s wps 20.12K ppl 53.16 gN 2.98 bleu 3.54, Mon Nov  4 19:46:43 2019\n",
            "  step 5500 lr 1 step-time 0.17s wps 32.36K ppl 53.49 gN 2.96 bleu 3.54, Mon Nov  4 19:47:01 2019\n",
            "  step 5600 lr 1 step-time 0.16s wps 36.29K ppl 52.44 gN 2.93 bleu 3.54, Mon Nov  4 19:47:16 2019\n",
            "  step 5700 lr 1 step-time 0.15s wps 36.48K ppl 51.87 gN 2.95 bleu 3.54, Mon Nov  4 19:47:32 2019\n",
            "  step 5800 lr 1 step-time 0.15s wps 36.09K ppl 51.36 gN 2.91 bleu 3.54, Mon Nov  4 19:47:47 2019\n",
            "  step 5900 lr 1 step-time 0.16s wps 36.08K ppl 51.73 gN 2.90 bleu 3.54, Mon Nov  4 19:48:03 2019\n",
            "  step 6000 lr 1 step-time 0.16s wps 36.07K ppl 52.00 gN 3.03 bleu 3.54, Mon Nov  4 19:48:18 2019\n",
            "# Save eval, global step 6000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1104 19:48:18.852955 139681884108672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "I1104 19:48:19.032862 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000, time 0.06s\n",
            "  # 522\n",
            "    src: Gi l cu hi u tin ca ngy hm nay , Bn c sn sng  nghe v vn  qu ti trong la chn ?\n",
            "    ref: So for my first question for you today : Are you guys ready to hear about the choice overload problem ?\n",
            "    nmt: Now , what &apos;s interesting about this question , how do you have a <unk> of life ?\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "I1104 19:48:19.158670 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000, time 0.06s\n",
            "  eval dev: perplexity 42.65, time 1s, Mon Nov  4 19:48:20 2019.\n",
            "  eval test: perplexity 49.30, time 1s, Mon Nov  4 19:48:21 2019.\n",
            "  step 6100 lr 1 step-time 0.16s wps 36.21K ppl 50.74 gN 2.87 bleu 3.54, Mon Nov  4 19:48:37 2019\n",
            "  step 6200 lr 1 step-time 0.15s wps 36.27K ppl 49.68 gN 2.93 bleu 3.54, Mon Nov  4 19:48:52 2019\n",
            "# Finished an epoch, step 6258. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "I1104 19:49:01.935225 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000, time 0.05s\n",
            "  # 114\n",
            "    src: Ti khng bit .\n",
            "    ref: I don &apos;t know .\n",
            "    nmt: I don &apos;t know .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "I1104 19:49:02.019218 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-6000, time 0.05s\n",
            "# External evaluation, global step 6000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 10s, Mon Nov  4 19:49:12 2019.\n",
            "  bleu dev: 4.4\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 6000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 10s, Mon Nov  4 19:49:23 2019.\n",
            "  bleu test: 3.2\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 6300 lr 1 step-time 0.22s wps 25.82K ppl 49.25 gN 3.10 bleu 4.38, Mon Nov  4 19:49:36 2019\n",
            "  step 6400 lr 1 step-time 0.29s wps 19.31K ppl 46.82 gN 2.99 bleu 4.38, Mon Nov  4 19:50:05 2019\n",
            "  step 6500 lr 1 step-time 0.23s wps 24.60K ppl 47.45 gN 2.94 bleu 4.38, Mon Nov  4 19:50:27 2019\n",
            "  step 6600 lr 1 step-time 0.16s wps 36.27K ppl 47.50 gN 3.06 bleu 4.38, Mon Nov  4 19:50:43 2019\n",
            "  step 6700 lr 1 step-time 0.15s wps 36.17K ppl 46.83 gN 2.94 bleu 4.38, Mon Nov  4 19:50:58 2019\n",
            "  step 6800 lr 1 step-time 0.15s wps 36.30K ppl 46.95 gN 2.97 bleu 4.38, Mon Nov  4 19:51:14 2019\n",
            "  step 6900 lr 1 step-time 0.16s wps 36.42K ppl 47.30 gN 3.01 bleu 4.38, Mon Nov  4 19:51:30 2019\n",
            "  step 7000 lr 1 step-time 0.15s wps 36.16K ppl 46.07 gN 2.94 bleu 4.38, Mon Nov  4 19:51:45 2019\n",
            "# Save eval, global step 7000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "I1104 19:51:45.708626 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000, time 0.05s\n",
            "  # 128\n",
            "    src:  l l do ti sao ti mun ni v sc mnh ca bn sc nhn cch\n",
            "    ref: And so I want to talk about the power of identity .\n",
            "    nmt: That &apos;s why I think that &apos;s what we need to do with the world .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "I1104 19:51:45.817349 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000, time 0.06s\n",
            "  eval dev: perplexity 39.55, time 1s, Mon Nov  4 19:51:47 2019.\n",
            "  eval test: perplexity 45.55, time 1s, Mon Nov  4 19:51:48 2019.\n",
            "  step 7100 lr 1 step-time 0.16s wps 36.22K ppl 47.29 gN 3.01 bleu 4.38, Mon Nov  4 19:52:04 2019\n",
            "  step 7200 lr 1 step-time 0.16s wps 36.22K ppl 46.23 gN 2.96 bleu 4.38, Mon Nov  4 19:52:19 2019\n",
            "  step 7300 lr 1 step-time 0.15s wps 36.07K ppl 46.05 gN 2.97 bleu 4.38, Mon Nov  4 19:52:35 2019\n",
            "# Finished an epoch, step 7301. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "I1104 19:52:35.338815 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000, time 0.06s\n",
            "  # 1503\n",
            "    src: H tm kim s giu c t hot ng trn mng , thng qua cc cch thc bt hp php nh vic s dng cc trojans tn cng h thng ngn hng  ly cp tin t ti khon ca chng ta khi chng ta thc hin cc giao dch trc tuyn hoc vi cc phn mm ghi li thao tc bn phm gip h c c thng tin th tn dng khi chng ta mua hng trc tuyn t nhng my tnh b ly nhim .\n",
            "    ref: These guys make their fortunes online , but they make it through the illegal means of using things like banking trojans to steal money from our bank accounts while we do online banking , or with keyloggers to collect our credit card information while we are doing online shopping from an infected computer .\n",
            "    nmt: They &apos;re using the <unk> of our <unk> , which we &apos;re going to see the <unk> of our <unk> , which we &apos;re going to see the <unk> of the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the <unk> , the\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "I1104 19:52:35.606478 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-7000, time 0.05s\n",
            "# External evaluation, global step 7000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 11s, Mon Nov  4 19:52:47 2019.\n",
            "  bleu dev: 4.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 7000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 11s, Mon Nov  4 19:52:58 2019.\n",
            "  bleu test: 3.9\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 7400 lr 1 step-time 0.30s wps 18.75K ppl 43.24 gN 3.13 bleu 4.77, Mon Nov  4 19:53:28 2019\n",
            "  step 7500 lr 1 step-time 0.28s wps 19.64K ppl 42.81 gN 2.99 bleu 4.77, Mon Nov  4 19:53:57 2019\n",
            "  step 7600 lr 1 step-time 0.16s wps 36.18K ppl 44.03 gN 3.09 bleu 4.77, Mon Nov  4 19:54:12 2019\n",
            "  step 7700 lr 1 step-time 0.16s wps 36.22K ppl 43.67 gN 3.07 bleu 4.77, Mon Nov  4 19:54:28 2019\n",
            "  step 7800 lr 1 step-time 0.16s wps 36.02K ppl 43.40 gN 2.94 bleu 4.77, Mon Nov  4 19:54:43 2019\n",
            "  step 7900 lr 1 step-time 0.15s wps 36.23K ppl 42.54 gN 3.01 bleu 4.77, Mon Nov  4 19:54:59 2019\n",
            "  step 8000 lr 1 step-time 0.15s wps 36.33K ppl 42.90 gN 2.99 bleu 4.77, Mon Nov  4 19:55:14 2019\n",
            "# Save eval, global step 8000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "I1104 19:55:14.906550 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000, time 0.06s\n",
            "  # 963\n",
            "    src: Vic k chuyn ang tr nn ngy cng a gic quan .\n",
            "    ref: Storytelling is becoming more and more multi-sensorial .\n",
            "    nmt: It &apos;s about the same thing to do with the future .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "I1104 19:55:15.011392 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000, time 0.06s\n",
            "  eval dev: perplexity 38.48, time 1s, Mon Nov  4 19:55:16 2019.\n",
            "  eval test: perplexity 44.71, time 1s, Mon Nov  4 19:55:17 2019.\n",
            "  step 8100 lr 1 step-time 0.16s wps 36.08K ppl 43.10 gN 2.97 bleu 4.77, Mon Nov  4 19:55:33 2019\n",
            "  step 8200 lr 1 step-time 0.16s wps 36.16K ppl 43.28 gN 3.05 bleu 4.77, Mon Nov  4 19:55:48 2019\n",
            "  step 8300 lr 1 step-time 0.16s wps 36.12K ppl 42.88 gN 3.04 bleu 4.77, Mon Nov  4 19:56:04 2019\n",
            "# Finished an epoch, step 8344. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "I1104 19:56:11.456929 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000, time 0.05s\n",
            "  # 913\n",
            "    src: Video ca Vy l ti nhn v pht v  khng i xe p trong ng ln ng dnh cho xe p , nhng thng c nhng vt cn khin bn khng i ng vo ln ng dnh cho xe p .\n",
            "    ref: So I got a ticket for not riding in the bike lane , but often there are obstructions that keep you from properly riding in the bike lane .\n",
            "    nmt: My <unk> is that I was not <unk> <unk> , but it doesn &apos;t work with the <unk> <unk> , but it &apos;s not just a <unk> <unk> , but it &apos;s not just a <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "I1104 19:56:11.616245 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-8000, time 0.05s\n",
            "# External evaluation, global step 8000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 11s, Mon Nov  4 19:56:22 2019.\n",
            "  bleu dev: 4.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 8000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 11s, Mon Nov  4 19:56:34 2019.\n",
            "  bleu test: 3.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 8400 lr 1 step-time 0.23s wps 24.28K ppl 41.48 gN 3.21 bleu 4.83, Mon Nov  4 19:56:50 2019\n",
            "  step 8500 lr 1 step-time 0.28s wps 19.92K ppl 40.08 gN 3.02 bleu 4.83, Mon Nov  4 19:57:18 2019\n",
            "  step 8600 lr 1 step-time 0.22s wps 25.78K ppl 40.57 gN 3.11 bleu 4.83, Mon Nov  4 19:57:40 2019\n",
            "  step 8700 lr 1 step-time 0.16s wps 36.24K ppl 40.36 gN 3.00 bleu 4.83, Mon Nov  4 19:57:56 2019\n",
            "  step 8800 lr 1 step-time 0.15s wps 36.21K ppl 40.73 gN 3.04 bleu 4.83, Mon Nov  4 19:58:11 2019\n",
            "  step 8900 lr 1 step-time 0.16s wps 36.02K ppl 40.30 gN 3.06 bleu 4.83, Mon Nov  4 19:58:27 2019\n",
            "  step 9000 lr 1 step-time 0.15s wps 36.29K ppl 39.89 gN 3.09 bleu 4.83, Mon Nov  4 19:58:42 2019\n",
            "# Save eval, global step 9000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "I1104 19:58:42.922681 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000, time 0.06s\n",
            "  # 410\n",
            "    src: Ti cho rng  l iu m chng ta cn phi thay i .\n",
            "    ref: And I think that &apos;s the orientation that we have to change .\n",
            "    nmt: I think it &apos;s good for us to change .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "I1104 19:58:43.034467 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000, time 0.06s\n",
            "  eval dev: perplexity 35.69, time 1s, Mon Nov  4 19:58:44 2019.\n",
            "  eval test: perplexity 40.95, time 1s, Mon Nov  4 19:58:45 2019.\n",
            "  step 9100 lr 1 step-time 0.16s wps 36.20K ppl 40.10 gN 3.03 bleu 4.83, Mon Nov  4 19:59:01 2019\n",
            "  step 9200 lr 1 step-time 0.15s wps 36.14K ppl 39.84 gN 2.97 bleu 4.83, Mon Nov  4 19:59:16 2019\n",
            "  step 9300 lr 1 step-time 0.16s wps 36.32K ppl 40.27 gN 3.03 bleu 4.83, Mon Nov  4 19:59:32 2019\n",
            "# Finished an epoch, step 9387. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "I1104 19:59:45.824372 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000, time 0.06s\n",
            "  # 925\n",
            "    src: Cm n cc bn .\n",
            "    ref: Thank you .\n",
            "    nmt: Thank you .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "I1104 19:59:45.908790 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-9000, time 0.06s\n",
            "# External evaluation, global step 9000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 10s, Mon Nov  4 19:59:56 2019.\n",
            "  bleu dev: 5.6\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 9000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 9s, Mon Nov  4 20:00:06 2019.\n",
            "  bleu test: 4.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 9400 lr 1 step-time 0.18s wps 30.57K ppl 39.41 gN 3.18 bleu 5.61, Mon Nov  4 20:00:11 2019\n",
            "  step 9500 lr 1 step-time 0.27s wps 20.39K ppl 37.40 gN 3.01 bleu 5.61, Mon Nov  4 20:00:38 2019\n",
            "  step 9600 lr 1 step-time 0.28s wps 20.30K ppl 37.44 gN 3.08 bleu 5.61, Mon Nov  4 20:01:06 2019\n",
            "  step 9700 lr 1 step-time 0.15s wps 36.18K ppl 37.63 gN 3.05 bleu 5.61, Mon Nov  4 20:01:21 2019\n",
            "  step 9800 lr 1 step-time 0.16s wps 36.40K ppl 38.05 gN 3.10 bleu 5.61, Mon Nov  4 20:01:37 2019\n",
            "  step 9900 lr 1 step-time 0.15s wps 36.43K ppl 38.61 gN 3.08 bleu 5.61, Mon Nov  4 20:01:52 2019\n",
            "  step 10000 lr 1 step-time 0.16s wps 36.26K ppl 38.35 gN 3.09 bleu 5.61, Mon Nov  4 20:02:08 2019\n",
            "# Save eval, global step 10000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "I1104 20:02:08.761749 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000, time 0.06s\n",
            "  # 770\n",
            "    src: V trong mt ngy nhiu my , c khe h gia cc m my v mt tri l dng v ti thc mc , chc l ti c th cm thy kh hn mt ln na .\n",
            "    ref: And on a cloudy day , there was a crack in the clouds and the sun started to come out and I wondered , maybe I could feel better again .\n",
            "    nmt: And one of the <unk> , and I could see the <unk> of the <unk> , and I could feel that I could have a little bit more than the other time .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "I1104 20:02:08.909429 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000, time 0.06s\n",
            "  eval dev: perplexity 34.20, time 1s, Mon Nov  4 20:02:10 2019.\n",
            "  eval test: perplexity 39.59, time 1s, Mon Nov  4 20:02:11 2019.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "I1104 20:02:11.766770 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000, time 0.06s\n",
            "  # 778\n",
            "    src: Ti xem c hng anh ta , n hi hng hng .\n",
            "    ref: I looked at his throat , it was a little bit pink .\n",
            "    nmt: I saw him a little bit , and he &apos;s very excited .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "I1104 20:02:11.871878 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000, time 0.05s\n",
            "# External evaluation, global step 10000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 10s, Mon Nov  4 20:02:22 2019.\n",
            "  bleu dev: 5.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 10000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 10s, Mon Nov  4 20:02:33 2019.\n",
            "  bleu test: 4.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 10100 lr 1 step-time 0.16s wps 35.92K ppl 38.09 gN 3.01 bleu 5.69, Mon Nov  4 20:02:49 2019\n",
            "  step 10200 lr 1 step-time 0.15s wps 36.02K ppl 37.25 gN 2.97 bleu 5.69, Mon Nov  4 20:03:04 2019\n",
            "  step 10300 lr 1 step-time 0.16s wps 36.29K ppl 38.12 gN 3.05 bleu 5.69, Mon Nov  4 20:03:20 2019\n",
            "  step 10400 lr 1 step-time 0.16s wps 35.97K ppl 37.52 gN 3.00 bleu 5.69, Mon Nov  4 20:03:35 2019\n",
            "# Finished an epoch, step 10430. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "I1104 20:03:40.254520 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000, time 0.06s\n",
            "  # 72\n",
            "    src: Bc xp hnh cn mt mnh na .\n",
            "    ref: There had to be another piece of the jigsaw .\n",
            "    nmt: The other is a little bit more than the same .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "I1104 20:03:40.352287 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-10000, time 0.05s\n",
            "# External evaluation, global step 10000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 10s, Mon Nov  4 20:03:50 2019.\n",
            "  bleu dev: 5.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 10000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 10s, Mon Nov  4 20:04:01 2019.\n",
            "  bleu test: 4.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 10500 lr 1 step-time 0.25s wps 22.23K ppl 35.88 gN 3.27 bleu 5.69, Mon Nov  4 20:04:21 2019\n",
            "  step 10600 lr 1 step-time 0.28s wps 19.65K ppl 35.17 gN 3.07 bleu 5.69, Mon Nov  4 20:04:50 2019\n",
            "  step 10700 lr 1 step-time 0.20s wps 28.30K ppl 35.78 gN 3.09 bleu 5.69, Mon Nov  4 20:05:10 2019\n",
            "  step 10800 lr 1 step-time 0.16s wps 36.44K ppl 36.29 gN 3.11 bleu 5.69, Mon Nov  4 20:05:25 2019\n",
            "  step 10900 lr 1 step-time 0.16s wps 36.29K ppl 36.21 gN 3.14 bleu 5.69, Mon Nov  4 20:05:41 2019\n",
            "  step 11000 lr 1 step-time 0.16s wps 36.09K ppl 36.20 gN 3.07 bleu 5.69, Mon Nov  4 20:05:56 2019\n",
            "# Save eval, global step 11000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "I1104 20:05:57.157835 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000, time 0.05s\n",
            "  # 140\n",
            "    src: b m ti cht n mc ti thy kh th ri sau  b  ti i\n",
            "    ref: And she &apos;d squeeze me so tight I could barely breathe and then she &apos;d let me go .\n",
            "    nmt: And she &apos;s my mother &apos;s mother &apos;s mother &apos;s mother &apos;s mother and I &apos;m going to die .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "I1104 20:05:57.279506 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000, time 0.06s\n",
            "  eval dev: perplexity 34.02, time 1s, Mon Nov  4 20:05:58 2019.\n",
            "  eval test: perplexity 39.85, time 1s, Mon Nov  4 20:05:59 2019.\n",
            "  step 11100 lr 1 step-time 0.15s wps 36.15K ppl 36.16 gN 3.08 bleu 5.69, Mon Nov  4 20:06:15 2019\n",
            "  step 11200 lr 1 step-time 0.16s wps 36.51K ppl 36.34 gN 3.08 bleu 5.69, Mon Nov  4 20:06:31 2019\n",
            "  step 11300 lr 1 step-time 0.15s wps 36.00K ppl 35.63 gN 3.02 bleu 5.69, Mon Nov  4 20:06:46 2019\n",
            "  step 11400 lr 1 step-time 0.15s wps 36.37K ppl 35.49 gN 3.07 bleu 5.69, Mon Nov  4 20:07:01 2019\n",
            "# Finished an epoch, step 11473. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "I1104 20:07:13.214077 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000, time 0.06s\n",
            "  # 32\n",
            "    src: Mi t cc ca hng n t khp th gii .\n",
            "    ref: The smells from shop doors were from the rest of the world .\n",
            "    nmt: <unk> from the world &apos;s world &apos;s world .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "I1104 20:07:13.311565 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-11000, time 0.05s\n",
            "# External evaluation, global step 11000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 10s, Mon Nov  4 20:07:24 2019.\n",
            "  bleu dev: 5.3\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 11000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 11s, Mon Nov  4 20:07:36 2019.\n",
            "  bleu test: 4.4\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "  step 11500 lr 1 step-time 0.19s wps 28.10K ppl 35.53 gN 3.21 bleu 5.69, Mon Nov  4 20:07:44 2019\n",
            "  step 11600 lr 1 step-time 0.27s wps 20.92K ppl 34.09 gN 3.13 bleu 5.69, Mon Nov  4 20:08:11 2019\n",
            "  step 11700 lr 1 step-time 0.26s wps 21.49K ppl 33.75 gN 3.09 bleu 5.69, Mon Nov  4 20:08:37 2019\n",
            "  step 11800 lr 1 step-time 0.16s wps 36.03K ppl 34.27 gN 3.13 bleu 5.69, Mon Nov  4 20:08:53 2019\n",
            "  step 11900 lr 1 step-time 0.16s wps 36.21K ppl 34.32 gN 3.09 bleu 5.69, Mon Nov  4 20:09:08 2019\n",
            "  step 12000 lr 1 step-time 0.15s wps 35.92K ppl 33.64 gN 3.05 bleu 5.69, Mon Nov  4 20:09:24 2019\n",
            "# Save eval, global step 12000\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "I1104 20:09:24.476528 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000, time 0.06s\n",
            "  # 429\n",
            "    src: Vy th iu g xy ra ti y ?\n",
            "    ref: So what happens here ?\n",
            "    nmt: So what happened ?\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "I1104 20:09:24.567092 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000, time 0.06s\n",
            "  eval dev: perplexity 32.55, time 1s, Mon Nov  4 20:09:26 2019.\n",
            "  eval test: perplexity 37.37, time 1s, Mon Nov  4 20:09:27 2019.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "I1104 20:09:27.472690 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000, time 0.05s\n",
            "  # 694\n",
            "    src: Ti hc thuc trong lp gii phu im bt u v hot ng ca tng b c , tng nhnh ca tng ng mch tch ra t ng mch ch , nhng cn bnh phc tp , c him gp v thng dng .\n",
            "    ref: I memorized in my anatomy class the origins and exertions of every muscle , every branch of every artery that came off the aorta , differential diagnoses obscure and common .\n",
            "    nmt: I started to have the same <unk> , and the <unk> of the brain , the <unk> of the brain , the <unk> and the <unk> and the <unk> .\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "I1104 20:09:27.623613 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000, time 0.06s\n",
            "  eval dev: perplexity 32.55, time 1s, Mon Nov  4 20:09:29 2019.\n",
            "  eval test: perplexity 37.37, time 1s, Mon Nov  4 20:09:30 2019.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "I1104 20:09:30.280607 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/translate.ckpt-12000, time 0.06s\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 9s, Mon Nov  4 20:09:40 2019.\n",
            "  bleu dev: 5.6\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 12000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 9s, Mon Nov  4 20:09:49 2019.\n",
            "  bleu test: 4.8\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# Final, step 12000 lr 1 step-time 0.15s wps 35.92K ppl 33.64 gN 3.05 dev ppl 32.55, dev bleu 5.6, test ppl 37.37, test bleu 4.8, Mon Nov  4 20:09:50 2019\n",
            "# Done training!, time 2546s, Mon Nov  4 20:09:50 2019.\n",
            "# Start evaluating saved best models.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000\n",
            "I1104 20:09:50.269024 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000, time 0.06s\n",
            "  # 1263\n",
            "    src: 1 ch chut opossum sao ? Th kim tra xem . Cn sng ? ng vy .\n",
            "    ref: Opossum ? Check . Living ? Yep .\n",
            "    nmt: A <unk> ? How ? What &apos;s the <unk> ?\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000\n",
            "I1104 20:09:50.369862 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000\n",
            "  loaded eval model parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000, time 0.06s\n",
            "  eval dev: perplexity 34.20, time 1s, Mon Nov  4 20:09:51 2019.\n",
            "  eval test: perplexity 39.59, time 1s, Mon Nov  4 20:09:53 2019.\n",
            "INFO:tensorflow:Restoring parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000\n",
            "I1104 20:09:53.071283 139681884108672 saver.py:1284] Restoring parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000\n",
            "  loaded infer model parameters from /content/nmt/tmp/nmt_model/best_bleu/translate.ckpt-10000, time 0.05s\n",
            "# External evaluation, global step 10000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 9s, Mon Nov  4 20:10:02 2019.\n",
            "  bleu dev: 5.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# External evaluation, global step 10000\n",
            "  decoding to output /content/nmt/tmp/nmt_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 9s, Mon Nov  4 20:10:12 2019.\n",
            "  bleu test: 4.7\n",
            "  saving hparams to /content/nmt/tmp/nmt_model/hparams\n",
            "# Best bleu, step 10000 lr 1 step-time 0.15s wps 35.92K ppl 33.64 gN 3.05 dev ppl 34.20, dev bleu 5.7, test ppl 39.59, test bleu 4.7, Mon Nov  4 20:10:12 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwxfAIs14pGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV4KzpHQEKbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cqmqtD2ETU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXND2NZfET8D",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:23989/content/nmt/tmp/nmt_model": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNTAxIChOb3QgSW1wbGVtZW50ZWQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj41MDEuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1455"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 501,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "20b390cd-2dba-4778-9a19-3628122f13e3"
      },
      "source": [
        "files.download( \"/content/nmt/tmp/nmt_model\" )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-06d48512e19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/nmt/tmp/nmt_model\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Failed to download: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC0OSBaIEhpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}